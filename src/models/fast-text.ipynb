{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "ft = fasttext.load_model('/Users/davidhunt/Documents/fastText/cc.en.300.bin')\n",
    "ft.get_dimension()\n",
    "\n",
    "fasttext.util.reduce_model(ft, 100)\n",
    "ft.get_dimension()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FIERCE' 'DEEP' 'INTENSE' 'EXTREME' 'RAM' 'BUMP' 'BUTT' 'KNOCK' 'SNOW'\n",
       " 'NOISE' 'FUZZ' 'STATIC' 'PROUD' 'VIRGIN' 'HAIL' 'BLOODY']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#  Load the CSV file\n",
    "data = pd.read_csv(\"/Users/davidhunt/Documents/github/tamudatathon2024/data/formatted_data.csv\")\n",
    "\n",
    "# Pick a random row\n",
    "random_row = data.sample(n=1)\n",
    "\n",
    "# Extract columns 2-17 (index 1-16 in zero-based indexing)\n",
    "selected_columns = random_row.iloc[0, 1:17].values\n",
    "\n",
    "# Store in a 1D array\n",
    "words = np.array(selected_columns)\n",
    "\n",
    "print(words)\n",
    "\n",
    "\n",
    "\n",
    "embeds = [ft.get_word_vector(word) for word in words]\n",
    "\n",
    "groups = len(words) // 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster 1: ['BUMP', 'SNOW', 'PROUD', 'HAIL']\n",
       "Cluster 2: ['KNOCK', 'NOISE', 'FUZZ', 'STATIC']\n",
       "Cluster 3: ['RAM']\n",
       "Cluster 4: ['FIERCE', 'DEEP', 'INTENSE', 'EXTREME', 'BUTT', 'VIRGIN', 'BLOODY']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "similarities = cosine_similarity(embeds)\n",
    "# print(similarities)\n",
    "\n",
    "kmeans = KMeans(n_clusters=groups, random_state=0)\n",
    "#kmeans.fit(embeds)\n",
    "kmeans.fit(similarities)\n",
    "\n",
    "for i in range(4):\n",
    "    cluster_words = [words[j] for j in range(len(words)) if kmeans.labels_[j] == i]\n",
    "    print(f\"Cluster {i+1}: {cluster_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster 1: ['FIERCE', 'INTENSE', 'EXTREME', 'BLOODY']\n",
       "Average similarity (cohesion): 0.6368\n",
       "\n",
       "Cluster 2: ['RAM', 'PROUD', 'VIRGIN', 'HAIL']\n",
       "Average similarity (cohesion): 0.3428\n",
       "\n",
       "Cluster 3: ['BUMP', 'BUTT', 'KNOCK', 'SNOW']\n",
       "Average similarity (cohesion): 0.6092\n",
       "\n",
       "Cluster 4: ['DEEP', 'NOISE', 'FUZZ', 'STATIC']\n",
       "Average similarity (cohesion): 0.6577\n",
       "\n",
       "The most cohesive cluster is Cluster 4 with cohesion 0.6577\n",
       "['DEEP', 'NOISE', 'FUZZ', 'STATIC']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from k_means_constrained import KMeansConstrained\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "clf = KMeansConstrained(n_clusters=groups, size_min=4, size_max=4, random_state=42)\n",
    "# clusters = clf.fit_predict(embeds)\n",
    "clusters = clf.fit_predict(similarities)\n",
    "\n",
    "cluster_cohesion = {}\n",
    "most_cohesive_cluster = None\n",
    "mymax = -1\n",
    "\n",
    "for i in range(groups):\n",
    "    # Get indices of elements in the current cluster\n",
    "    cluster_indices = [j for j in range(len(words)) if clf.labels_[j] == i]\n",
    "    \n",
    "    # Extract similarities for the current cluster only\n",
    "    cluster_similarities = similarities[np.ix_(cluster_indices, cluster_indices)]\n",
    "    \n",
    "    # Calculate the average similarity (excluding self-similarity)\n",
    "    avg_similarity = np.mean(cluster_similarities[np.triu_indices(len(cluster_indices), k=1)])\n",
    "    cluster_cohesion[i] = avg_similarity\n",
    "    \n",
    "    # Print the words in each cluster for reference\n",
    "    cluster_words = [words[j] for j in cluster_indices]\n",
    "    print(f\"Cluster {i+1}: {cluster_words}\")\n",
    "    print(f\"Average similarity (cohesion): {avg_similarity:.4f}\\n\")\n",
    "\n",
    "    if avg_similarity > mymax:\n",
    "        mymax = avg_similarity\n",
    "        most_cohesive_words = cluster_words\n",
    "    \n",
    "\n",
    "# Find the cluster with the highest cohesion\n",
    "most_cohesive_cluster = max(cluster_cohesion, key=cluster_cohesion.get)\n",
    "print(f\"The most cohesive cluster is Cluster {most_cohesive_cluster + 1} with cohesion {cluster_cohesion[most_cohesive_cluster]:.4f}\")\n",
    "\n",
    "print(most_cohesive_words)\n",
    "# print(f\"Strongest cluster: {max(clf.cluster_centers_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('INTENSE', 'EXTREME'), 0.7851559), (('NOISE', 'FUZZ'), 0.72250944), (('KNOCK', 'BLOODY'), 0.69096476), (('BUMP', 'KNOCK'), 0.69085044), (('DEEP', 'STATIC'), 0.6837579), (('FUZZ', 'STATIC'), 0.67562854), (('FIERCE', 'INTENSE'), 0.6744777), (('EXTREME', 'NOISE'), 0.67093134), (('NOISE', 'STATIC'), 0.6577175), (('BUTT', 'KNOCK'), 0.6548339), (('KNOCK', 'FUZZ'), 0.6495125), (('BUTT', 'BLOODY'), 0.644129), (('KNOCK', 'NOISE'), 0.6438557), (('FIERCE', 'PROUD'), 0.64218885), (('VIRGIN', 'BLOODY'), 0.6386467), (('EXTREME', 'BLOODY'), 0.63531), (('DEEP', 'EXTREME'), 0.6295576), (('DEEP', 'INTENSE'), 0.6286102), (('EXTREME', 'STATIC'), 0.62820345), (('KNOCK', 'STATIC'), 0.62675816), (('STATIC', 'BLOODY'), 0.6257698), (('EXTREME', 'BUTT'), 0.6216041), (('KNOCK', 'HAIL'), 0.6211042), (('BUMP', 'BUTT'), 0.6186168), (('DEEP', 'NOISE'), 0.61550343), (('BUTT', 'PROUD'), 0.6125905), (('BUMP', 'SNOW'), 0.60809624), (('PROUD', 'HAIL'), 0.6051511), (('DEEP', 'KNOCK'), 0.60381556), (('HAIL', 'BLOODY'), 0.6010379), (('BUMP', 'FUZZ'), 0.5990737), (('NOISE', 'BLOODY'), 0.59650433), (('DEEP', 'BUTT'), 0.5947867), (('DEEP', 'BUMP'), 0.59341013), (('DEEP', 'FUZZ'), 0.5908385), (('INTENSE', 'STATIC'), 0.5900686), (('BUTT', 'FUZZ'), 0.5898768), (('FIERCE', 'EXTREME'), 0.58730215), (('EXTREME', 'FUZZ'), 0.58710307), (('FUZZ', 'BLOODY'), 0.5866705), (('BUMP', 'NOISE'), 0.58408433), (('STATIC', 'HAIL'), 0.582999), (('DEEP', 'BLOODY'), 0.5824584), (('FUZZ', 'HAIL'), 0.5816719), (('INTENSE', 'BLOODY'), 0.5803174), (('BUMP', 'STATIC'), 0.5776411), (('BUMP', 'HAIL'), 0.57719207), (('BUTT', 'STATIC'), 0.56628627), (('FIERCE', 'DEEP'), 0.5659364), (('SNOW', 'BLOODY'), 0.56179976), (('STATIC', 'VIRGIN'), 0.5608248), (('FIERCE', 'BLOODY'), 0.558356), (('FIERCE', 'BUTT'), 0.55630875), (('KNOCK', 'SNOW'), 0.554387), (('BUTT', 'NOISE'), 0.54961973), (('INTENSE', 'BUTT'), 0.5423098), (('DEEP', 'SNOW'), 0.5412229), (('DEEP', 'VIRGIN'), 0.54072225), (('KNOCK', 'VIRGIN'), 0.5406831), (('INTENSE', 'NOISE'), 0.5378618), (('EXTREME', 'KNOCK'), 0.53601986), (('EXTREME', 'VIRGIN'), 0.5319393), (('EXTREME', 'BUMP'), 0.53091127), (('EXTREME', 'SNOW'), 0.5294133), (('SNOW', 'STATIC'), 0.5293249), (('BUTT', 'SNOW'), 0.52832973), (('FIERCE', 'KNOCK'), 0.5269122), (('FIERCE', 'FUZZ'), 0.5253922), (('DEEP', 'HAIL'), 0.52339643), (('BUMP', 'BLOODY'), 0.52275443), (('INTENSE', 'FUZZ'), 0.5186192), (('PROUD', 'BLOODY'), 0.51756924), (('VIRGIN', 'HAIL'), 0.51712435), (('BUTT', 'VIRGIN'), 0.5152126), (('NOISE', 'HAIL'), 0.513476), (('EXTREME', 'PROUD'), 0.51180506), (('FIERCE', 'HAIL'), 0.5087374), (('FUZZ', 'VIRGIN'), 0.50732243), (('BUTT', 'HAIL'), 0.50020343), (('INTENSE', 'KNOCK'), 0.49941832), (('INTENSE', 'SNOW'), 0.49875036), (('SNOW', 'HAIL'), 0.49833742), (('SNOW', 'NOISE'), 0.49801812), (('FIERCE', 'NOISE'), 0.4969628), (('BUMP', 'PROUD'), 0.49356115), (('FIERCE', 'VIRGIN'), 0.48750132), (('KNOCK', 'PROUD'), 0.48400235), (('INTENSE', 'VIRGIN'), 0.4745866), (('EXTREME', 'HAIL'), 0.47334158), (('NOISE', 'VIRGIN'), 0.4724914), (('FIERCE', 'STATIC'), 0.4673548), (('FIERCE', 'BUMP'), 0.4636328), (('FIERCE', 'SNOW'), 0.46354157), (('INTENSE', 'BUMP'), 0.45973015), (('SNOW', 'FUZZ'), 0.45900124), (('SNOW', 'PROUD'), 0.447937), (('NOISE', 'PROUD'), 0.44386142), (('PROUD', 'VIRGIN'), 0.44370088), (('FUZZ', 'PROUD'), 0.44243813), (('DEEP', 'PROUD'), 0.4420807), (('INTENSE', 'PROUD'), 0.44112894), (('INTENSE', 'HAIL'), 0.43371102), (('STATIC', 'PROUD'), 0.42535177), (('RAM', 'STATIC'), 0.4235037), (('SNOW', 'VIRGIN'), 0.42301393), (('BUMP', 'VIRGIN'), 0.3797699), (('RAM', 'FUZZ'), 0.34801802), (('RAM', 'KNOCK'), 0.32398728), (('RAM', 'NOISE'), 0.3193267), (('RAM', 'BLOODY'), 0.26593104), (('RAM', 'BUTT'), 0.26424322), (('EXTREME', 'RAM'), 0.2581929), (('RAM', 'BUMP'), 0.25572035), (('RAM', 'HAIL'), 0.2414702), (('RAM', 'VIRGIN'), 0.20619793), (('DEEP', 'RAM'), 0.20405115), (('INTENSE', 'RAM'), 0.14086154), (('RAM', 'SNOW'), 0.081428185), (('FIERCE', 'RAM'), 0.058943346), (('RAM', 'PROUD'), 0.042971093)]\n",
       "              Word Pair  Similarity\n",
       "0    (INTENSE, EXTREME)    0.785156\n",
       "1         (NOISE, FUZZ)    0.722509\n",
       "2       (KNOCK, BLOODY)    0.690965\n",
       "3         (BUMP, KNOCK)    0.690850\n",
       "4        (DEEP, STATIC)    0.683758\n",
       "..                  ...         ...\n",
       "115         (DEEP, RAM)    0.204051\n",
       "116      (INTENSE, RAM)    0.140862\n",
       "117         (RAM, SNOW)    0.081428\n",
       "118       (FIERCE, RAM)    0.058943\n",
       "119        (RAM, PROUD)    0.042971\n",
       "\n",
       "[120 rows x 2 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "similarity_pairs = {}\n",
    "\n",
    "for i in range(len(words)):\n",
    "    for j in range(i + 1, len(words)):\n",
    "        similarity_pairs[(words[i], words[j])] = similarities[i, j]\n",
    "\n",
    "# Sort the list of pairs by similarity in descending order\n",
    "similarity_pairs_list = sorted(similarity_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Convert to a DataFrame for easier viewing\n",
    "similarity_df = pd.DataFrame(similarity_pairs_list, columns=[\"Word Pair\", \"Similarity\"])\n",
    "\n",
    "print(similarity_pairs_list)\n",
    "print(similarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(list1, list2):\n",
    "    scores = []\n",
    "    for word in list1:\n",
    "        score = 0\n",
    "        for word2 in list2:\n",
    "            if word != word2:\n",
    "                score += similarity_pairs.get((word, word2), similarity_pairs.get((word2, word)))\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def find_most_dissimilar(list):\n",
    "    scores = get_scores(list, list)\n",
    "    print(scores.index(min(scores)))\n",
    "    return scores.index(min(scores))\n",
    "\n",
    "def find_next_similar(list1, list2, priority = 2):\n",
    "    scores = get_scores(list1, list2)\n",
    "    print(words[scores.index(max(scores))])\n",
    "    print(scores.index(max(scores)))\n",
    "    return words[scores.index(max(scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BUMP', 'BUTT', 'KNOCK', 'SNOW']\n",
       "BLOODY\n",
       "15\n",
       "3\n",
       "['BUMP', 'BUTT', 'KNOCK', 'BLOODY']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isOneAway = True\n",
    "last = ['BUMP', 'BUTT', 'KNOCK', 'SNOW']\n",
    "prev = [['BUMP', 'BUTT', 'KNOCK', 'SNOW']]\n",
    "\n",
    "if (isOneAway):\n",
    "    guess = last\n",
    "    print(guess)\n",
    "    # guess.remove(guess[find_most_dissimilar(guess)]) # kicks out least similar word\n",
    "    guess[find_most_dissimilar(guess)] = (find_next_similar(words, guess)) # adds most similar word\n",
    "    if not guess in prev:\n",
    "        prev.append(guess)\n",
    "    print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'numpy.ndarray'>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
